{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e105226b977247daace3da58de0ed080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bc78c0e906074ab482b6e0389d71291c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca01b1c80c0f407d97e4b1ad7b8447ce",
              "IPY_MODEL_e10a0518aca54148930fac0d4050b9d7"
            ]
          }
        },
        "bc78c0e906074ab482b6e0389d71291c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "ca01b1c80c0f407d97e4b1ad7b8447ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5b9985a10f384292b2b1c3b695e9668d",
            "_dom_classes": [],
            "description": "Testing: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93df6f198c2047ab9df5bd70e39063f1"
          }
        },
        "e10a0518aca54148930fac0d4050b9d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_93693ddb73414de198f20e1c2ae64f48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25/25 [04:24&lt;00:00, 10.58s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0050e3499e94966a776c2e810fa4fd5"
          }
        },
        "5b9985a10f384292b2b1c3b695e9668d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93df6f198c2047ab9df5bd70e39063f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93693ddb73414de198f20e1c2ae64f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0050e3499e94966a776c2e810fa4fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f53f5a5cbdb4f18b9dc5f5c5ee1c9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_724298eb1dc342a5a347c202e2056746",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d310fae70f6f4076b23d6d8542a186fd",
              "IPY_MODEL_ebcc303e761c498a95e978fa49d83852"
            ]
          }
        },
        "724298eb1dc342a5a347c202e2056746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "d310fae70f6f4076b23d6d8542a186fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bf5cd72fb7504a4ead18ea60e3f21d0f",
            "_dom_classes": [],
            "description": "Testing: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f24c886ee68647d584c558b12019fd84"
          }
        },
        "ebcc303e761c498a95e978fa49d83852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_668f4268daa1420584039d25b0c1efc5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25/25 [02:51&lt;00:00,  6.85s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7a6d831386a4e3e97c89becca7d06c4"
          }
        },
        "bf5cd72fb7504a4ead18ea60e3f21d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f24c886ee68647d584c558b12019fd84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "668f4268daa1420584039d25b0c1efc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7a6d831386a4e3e97c89becca7d06c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czVxYr4BWDID"
      },
      "source": [
        "# Projeto Final: Avaliação dos modelos \n",
        "\n",
        "Neste notebook serão avaliados os dois modelos propostos para o projeto final da disciplina IA376 de 2020/2.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Vsn_PCwfr2"
      },
      "source": [
        "# Dependências"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cUuFp9dWClR"
      },
      "source": [
        "!pip install datasets             --quiet\n",
        "!pip install efficientnet-pytorch --quiet\n",
        "!pip install transformers==3.5.1  --quiet\n",
        "!pip install pytorch-lightning    --quiet\n",
        "!pip install jsonlines            --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u_7ekeBWKC2",
        "outputId": "f7ffa1e8-784d-44a9-9b32-076f42bcba49"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import spacy\n",
        "import torch\n",
        "import datasets\n",
        "import jsonlines\n",
        "import collections\n",
        "import torchvision\n",
        "import efficientnet_pytorch\n",
        "import pytorch_lightning as pl\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageChops\n",
        "from random import randrange\n",
        "from datasets import load_dataset, list_datasets\n",
        "from torchvision import transforms, utils\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from tqdm.notebook import tqdm\n",
        "from matplotlib.pyplot import imshow\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "else: \n",
        "   dev = \"cpu\" \n",
        "print(dev, torch.cuda.get_device_name(0))\n",
        "device = torch.device(dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0 Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7YYfQ9LwClg"
      },
      "source": [
        "# Métricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PLpf0DVWMyX"
      },
      "source": [
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove extra whitespace.\"\"\"\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(lower(s))\n",
        "\n",
        "def get_tokens(s):\n",
        "    if not s: return []\n",
        "    return normalize_answer(s).split()\n",
        "\n",
        "def compute_exact(a_gold, a_pred):\n",
        "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
        "\n",
        "def compute_f1(a_gold, a_pred):\n",
        "    gold_toks = get_tokens(a_gold)\n",
        "    pred_toks = get_tokens(a_pred)\n",
        "    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
        "    num_same = sum(common.values())\n",
        "    if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
        "        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
        "        return int(gold_toks == pred_toks)\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(pred_toks)\n",
        "    recall = 1.0 * num_same / len(gold_toks)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDebW7WwMnm-"
      },
      "source": [
        "# Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IoL3DVlWRdn"
      },
      "source": [
        "class T5Finetuner(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, train_dataloader, val_dataloader, test_dataloader, params):\n",
        "        super(T5Finetuner, self).__init__()\n",
        "\n",
        "        self.params = params\n",
        "        \n",
        "        self._train_dataloader = train_dataloader\n",
        "        self._val_dataloader   = val_dataloader\n",
        "        self._test_dataloader  = test_dataloader\n",
        "\n",
        "        self.encoder = EfficientNet.from_pretrained(model_name='efficientnet-b0', \n",
        "                                                    advprop= params['advprop'])\n",
        "        self.decoder = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels=112, out_channels=\n",
        "                              self.decoder.config.d_model, kernel_size=1)\n",
        "\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "        self.learning_rate = params['learning_rate']\n",
        "\n",
        "    def Embeddings(self, images):\n",
        "\n",
        "        # Shape (N, 112, 16, 16)\n",
        "        features = model.encoder.extract_endpoints(images)[\"reduction_4\"] \n",
        "        features = self.cnn1(features)\n",
        "        embeddings = features.permute(0, 2, 3, 1).reshape(features.shape[0], -1, \n",
        "                                                          self.decoder.config.d_model)\n",
        "\n",
        "        return embeddings\n",
        "\n",
        "    def generate(self, embeddings):\n",
        "        ''' \n",
        "        A partir das features extraidas da EfNet, gera o texto com o \n",
        "        encoder + decoder do T5.\n",
        "        '''\n",
        "        max_length = self.params['max_seq_len']\n",
        "\n",
        "        # Add start of sequence token\n",
        "        decoded_ids = torch.full((embeddings.shape[0], 1),\n",
        "                                 self.decoder.config.decoder_start_token_id,\n",
        "                                 dtype=torch.long).to(embeddings.device)\n",
        "\n",
        "        encoder_hidden_states = self.decoder.get_encoder()(inputs_embeds=embeddings)\n",
        "\n",
        "        for step in range(max_length-1):\n",
        "            logits = self.decoder(decoder_input_ids=decoded_ids, \n",
        "                                  encoder_outputs=encoder_hidden_states)[0]\n",
        "            next_token_logits = logits[:, -1, :]\n",
        "\n",
        "            # Greedy decoding\n",
        "            next_token_id = next_token_logits.argmax(1).unsqueeze(-1)\n",
        "            \n",
        "            # Check if output is end of senquence for all batches\n",
        "            if torch.eq(next_token_id[:, -1], self.tokenizer.eos_token_id).all():\n",
        "                break\n",
        "\n",
        "            # Concatenate past ids with new id, keeping batch dimension\n",
        "            decoded_ids = torch.cat([decoded_ids, next_token_id], dim=-1)\n",
        "\n",
        "        return decoded_ids\n",
        "\n",
        "    def forward(self, batch): \n",
        "        images, labels, tokens = batch \n",
        "\n",
        "        embeddings = self.Embeddings(images)\n",
        "\n",
        "        if self.training:\n",
        "            outputs = self.decoder(inputs_embeds=embeddings,\n",
        "                                   decoder_input_ids=None, \n",
        "                                   labels=tokens, return_dict=True)\n",
        "            return outputs.loss\n",
        "        \n",
        "        else:\n",
        "            return self.generate(embeddings)\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx): \n",
        "        loss = self(batch)\n",
        "        self.log('loss', loss, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        pred_tokens = self(batch)\n",
        "        decoded_pred = [self.tokenizer.decode(tokens) for tokens in pred_tokens]\n",
        "        return {\"pred\": decoded_pred, \"target\": batch[1]}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        pred_tokens = self(batch)\n",
        "        decoded_pred = [self.tokenizer.decode(tokens) for tokens in pred_tokens]\n",
        "        return {\"pred\": decoded_pred, \"target\": batch[1]}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        trues = sum([list(x['target']) for x in outputs], [])\n",
        "        preds = sum([list(x['pred']) for x in outputs], [])\n",
        "        # Exibe um exemplo aleatório do conjunto de validação\n",
        "        n = randrange(len(trues))\n",
        "        print(f\"\\nSample Target: {trues[n]}\\nPrediction: {preds[n]}\\n\")\n",
        "\n",
        "        f1 = []\n",
        "        exact = []\n",
        "        for true, pred in zip(trues, preds):\n",
        "            f1.append(compute_f1(a_gold=true, a_pred=pred))\n",
        "            exact.append(compute_exact(a_gold=true, a_pred=pred))\n",
        "        f1 = np.mean(f1)\n",
        "        exact = np.mean(exact)\n",
        "\n",
        "        self.log(\"val_f1\", f1, prog_bar=True)\n",
        "        self.log(\"val_exact\", exact, prog_bar=True)\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        # Flatten dos targets e preds para arrays\n",
        "        trues = sum([list(x['target']) for x in outputs], [])\n",
        "        preds = sum([list(x['pred']) for x in outputs], [])\n",
        "\n",
        "        for random in range(5):\n",
        "            n = randrange(len(trues))\n",
        "            print(f\"\\nSample Target: {trues[n]}\\nPrediction: {preds[n]}\\n\")\n",
        "\n",
        "        f1 = []\n",
        "        exact = []\n",
        "        for true, pred in zip(trues, preds):\n",
        "            f1.append(compute_f1(a_gold=true, a_pred=pred))\n",
        "            exact.append(compute_exact(a_gold=true, a_pred=pred))\n",
        "        f1 = np.mean(f1)\n",
        "        exact = np.mean(exact)\n",
        "\n",
        "        self.log(\"test_f1\", f1, prog_bar=True)\n",
        "        self.log(\"test_exact\", exact, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(\n",
        "            [p for p in self.parameters() if p.requires_grad],\n",
        "            lr=self.learning_rate, eps=1e-08)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self._train_dataloader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self._val_dataloader\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self._test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX_Iv806x8lM"
      },
      "source": [
        "# Parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RVfPF0YWThl"
      },
      "source": [
        "params = {\n",
        "    'advprop': True,          \n",
        "    'batch_size': 8,\n",
        "    'max_seq_len': 128,\n",
        "    'learning_rate': 5e-4,\n",
        "    'max_epochs': 70,\n",
        "    'patience': 25,\n",
        "    'monitor_variable': 'val_f1',\n",
        "    'augmentation': 5\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8kuNHkh9BWg"
      },
      "source": [
        "# Modelo pré-treinado no Synthetic Word Dataset \n",
        "## ICDAR SROIE 2019 - Avaliação no conjunto de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvcvLu7jMvmT"
      },
      "source": [
        "resume_from_checkpoint = 'img2text-synteticworddataset--epoch=0-val_exact=0.95-v0.ckpt'\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus=1,\n",
        "    precision=32, \n",
        "    log_gpu_memory=True,\n",
        "    max_epochs=1,\n",
        "    check_val_every_n_epoch=1,\n",
        "    profiler=True,\n",
        "    callbacks=None,\n",
        "    progress_bar_refresh_rate=1,\n",
        "    resume_from_checkpoint=resume_from_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511,
          "referenced_widgets": [
            "e105226b977247daace3da58de0ed080",
            "bc78c0e906074ab482b6e0389d71291c",
            "ca01b1c80c0f407d97e4b1ad7b8447ce",
            "e10a0518aca54148930fac0d4050b9d7",
            "5b9985a10f384292b2b1c3b695e9668d",
            "93df6f198c2047ab9df5bd70e39063f1",
            "93693ddb73414de198f20e1c2ae64f48",
            "d0050e3499e94966a776c2e810fa4fd5"
          ]
        },
        "id": "njeNBJPi9b-q",
        "outputId": "3ef5c24f-a932-4659-8a2e-fae2f759be30"
      },
      "source": [
        "trainer.test(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e105226b977247daace3da58de0ed080",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Target: Company: SANYU STATIONERY SHOP Address: NO. 31G&33G, JALAN SETIA INDAH X ,U13/X 40170 SETIA ALAM\n",
            "Prediction: Company: MR. D.I.Y. (M) SDN BHD Address: LOT 1851-A & 1851-B, JALAN KPB 6, KAWASAN PERINDUSTRIAN BALAKONG, 43300 SERI KEMBANGAN, SELANGOR\n",
            "\n",
            "\n",
            "Sample Target: Company: MR. D.I.Y. (M) SDN BHD Address: LOT 1851-A & 1851-B, JALAN KPB 6, KAWASAN PERINDUSTRIAN BALAKONG, 43300 SERI KEMBANGAN, SELANGOR\n",
            "Prediction: Company: MR. D.I.Y. (M) SDN BHD Address: LOT 1851-A & 1851-B, JALAN KPB 6, KAWASAN PERINDUSTRIAN BALAKONG, 43300 SERI KEMBANGAN, SELANGOR\n",
            "\n",
            "\n",
            "Sample Target: Company: RESTAURANT JIAWEI JIAWEI HOUSE Address: 13, JLN TASIK UTAMA 8 MEDAN NIAGA DAMAI SG BESI 57000 KL\n",
            "Prediction: Company: MR. D.I.Y. (M) SDN BHD Address: LOT 1851-A & 1851-B, JALAN KPB 6, KAWASAN PERINDUSTRIAN BALAKONG, 43300 SERI KEMBANGAN, SELANGOR\n",
            "\n",
            "\n",
            "Sample Target: Company: SANYU STATIONERY SHOP Address: NO. 31G&33G, JALAN SETIA INDAH X ,U13/X 40170 SETIA ALAM\n",
            "Prediction: Company: MR. D.I.Y. (M) SDN BHD Address: LOT 1851-A & 1851-B, JALAN KPB 6, KAWASAN PERINDUSTRIAN BALAKONG, 43300 SERI KEMBANGAN, SELANGOR\n",
            "\n",
            "\n",
            "Sample Target: Company: DE LUXE CIRCLE FRESH MART SDN BHD Address: NO.89&91, JALAN UTAMA, TAMAN MUTIA RINI, 81300 SKUDAI, JOHOR.\n",
            "Prediction: Company: UNIHAKKA INTERNATIONAL SDN BHD Address: 12, JALAN TAMPOI 7/4,KAWASAN PERINDUSTRIAN TAMPOI,81200 JOHOR BAHRU,JOHOR\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_exact': 0.1407035175879397, 'test_f1': 0.3891333301270491}\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'test_exact': 0.1407035175879397, 'test_f1': 0.3891333301270491}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47_QklGV9QQm"
      },
      "source": [
        "# Modelo pré-treinado no Synthetic Word Dataset + Wikipédia\n",
        "## ICDAR SROIE 2019 - Avaliação no conjunto de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511,
          "referenced_widgets": [
            "0f53f5a5cbdb4f18b9dc5f5c5ee1c9da",
            "724298eb1dc342a5a347c202e2056746",
            "d310fae70f6f4076b23d6d8542a186fd",
            "ebcc303e761c498a95e978fa49d83852",
            "bf5cd72fb7504a4ead18ea60e3f21d0f",
            "f24c886ee68647d584c558b12019fd84",
            "668f4268daa1420584039d25b0c1efc5",
            "e7a6d831386a4e3e97c89becca7d06c4"
          ]
        },
        "id": "t-pMAf4mtgwS",
        "outputId": "2fb56fd4-44d8-48bc-c1de-971dc270a5fb"
      },
      "source": [
        "trainer.test(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f53f5a5cbdb4f18b9dc5f5c5ee1c9da",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Target: Company: AIK HUAT HARDWARE ENTERPRISE (SETIA ALAM) SDN BHD Address: NO. 17-G, JALAN SETIA INDAH (X) U13/X, SETIA ALAM, SEKSYEN U13, 40170 SHAH ALAM,\n",
            "Prediction: Company: AIK HUAT HARDWARE ENTERPRISE (SETIA ALAM) SDN BHD Address: NO. 17-G, JALAN SETIA INDAH (X) U13/X, SETIA ALAM, SEKSYEN U13, 40170 SHAH ALAM,\n",
            "\n",
            "\n",
            "Sample Target: Company: MR. D.I.Y. (M) SDN BHD Address: LOT 1851-A & 1851-B, JALAN KPB 6, KAWASAN PERINDUSTRIAN BALAKONG, 43300 SERI KEMBANGAN, SELANGOR\n",
            "Prediction: Company: MR. D.I.Y. (M) SDN BHD Address: LOT 1851-A & 1851-B, JALAN KPB 6, KAWASAN PERINDUSTRIAN BALAKONG, 43300 SERI KEMBANGAN, SELANGOR\n",
            "\n",
            "\n",
            "Sample Target: Company: GERBANG ALAF RESTAURANTS SDN BHD Address: LEVEL 6, BANGUNAN TH, DAMANSARA UPTOWN3 NO.3, JALAN SS21/39, 47400 PETALING JAYA SELANGOR\n",
            "Prediction: Company: YHM AEON TEBRAU CITY Address: S117, SECOND FLOOR, AEON TEBRAU CITY, 1, JALAN DESA TEBRAU, TAMAN DESA TEBRAU, 81100 JOHOR BAHRU, JOHOR.\n",
            "\n",
            "\n",
            "Sample Target: Company: MR. D.I.Y. (KUCHAI) SDN BHD Address: LOT 1851-A & 1851-B, JALAN KPB 6, KAWASAN PERINDUSTRIAN BALAKONG, 43300 SERI KEMBANGAN, SELANGOR\n",
            "Prediction: Company: MR. D.I.Y. SDN BHD Address: LOT 1851-A & 1851-B, JALAN KPB 6, KAWASAN PERINDUSTRIAN BALAKONG, 43300 SERI KEMBANGAN, SELANGOR\n",
            "\n",
            "\n",
            "Sample Target: Company: SANYU STATIONERY SHOP Address: NO. 31G&33G, JALAN SETIA INDAH X ,U13/X 40170 SETIA ALAM\n",
            "Prediction: Company: ANN GIAP TRADING SDN BHD Address: NO. 135, JALAN BANGI, 43500 SEMENYIH, SELANGOR\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_exact': 0.23115577889447236, 'test_f1': 0.4742705727864495}\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'test_exact': 0.23115577889447236, 'test_f1': 0.4742705727864495}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}